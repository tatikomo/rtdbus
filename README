Макет комплекса обмена сообщениями и доступа к БДРВ.

Используемые продукты и технологии
1. zeromq 3.2
2. eXtremeDB 3.5
3. google protobuf 2.4.1
4. google logging 1.6.0
5. xercesc 3.1.1
6. CodeSynthesis XSD XML Schema to C++ compiler 3.3.0

Архитектура передачи сообщений
--------------------------------------------------------------------------------
Между Клиентом и Брокером: DEALER (К) <=> ROUTER (Б)
Между Брокером и Обработчиком: ROUTER (Б) <=> DEALER (О)

Для прямого взаимодействия между Клиентом (К) и Обработчиком (О) нужно реализовать:
1. Каждый Сервис, помимо подключения к Брокеру (Б), создает сокет подписки SUB.
   Все (О) данного Сервиса имеют одинаковую подписку. Она передается в (Б) в сообщении
   READY
2. При получении данного сообщения (Б) заносит идентификатор подписки (строка типa
   "tcp://*.5555"?, может быть использовать в этом качестве само название Сервиса?)
3. Клиент, используя служебное сообщение (mmi.service?), запрашивает готовность и
   идентификатор подписки интересующего его Сервиса. Он создает два сокета - один для
   связи с (Б), второй - для прямого взаимодействия с (О). Проверить, возможно ли 
   использовать один сокет для (О), для связи с несколькими (О)
4. При необходимости, (К) может публиковать в канал подписки (О) нужного Сервиса
   свой запрос. Первый (О), получивший запрос, обрабатывает его и отправляет (К) на
   его приемный сокет типа DEALER. Проверить, может ли получать сокет данного типа
   одиночные сообщения).

Альтернатива: в (О) может быть несколько нитей для обслуживания запросов. Главный
процесс (О) получает запросы от (К) на сокет ROUTER, и передает из через inproc://workers
остальным своим нитям (смотри пример zguide/C/mtserver.c). Обмен ROUTER<->ROUTER возможен,
но не прост (согласно ZMQ guide).

ROUTER will route messages asynchronously to any peer connected to it, if you prefix the identity as the first frame of the message.
Think of REQ and DEALER sockets as "clients" and REP and ROUTER sockets as "servers"

ОТЛАДКА
--------------------------------------------------------------------------------
Для корректной работы valgrind при обработке программ с включенной библиотекой 
ZMQ необходимо использовать следующую командную строку:
valgrind --tool=memcheck --leak-check=full --suppressions=valgrind.supp someprog

Перед компиляцией создать ссылки для zmq.h zmq.hpp из cppzmq/include в zeromq/src.

XML
--------------------------------------------------------------------------------
Валидация XML по примеру статьи http://stackoverflow.com/questions/124865/xml-schema-xsd-validation-tool
1) xmllint --noout --schema XSD_FILE XML_FILE
2) StdInParse -n -s -f -v=always < XML_FILE
Онлайн-инструменты по валидации и сравнению версий XML-документов http://www.corefiling.com/opensource

XSD версии 3.3.0 содержит ошибки, привеодящие к множественным предупреждениям
компилятора gcc. Необходимо использовать флаг -fpermissive для успешной компиляции.
Версия 4.0 компилируется успешно без предупреждений компилятора.

Настройка отладочного вывода 
--------------------------------------------------------------------------------
Используется библиотека glog от GOOGLE, устанавливается в /usr/local
Использование GLOG
If the Google gflags library isn't installed, you set flags via environment variables, prefixing the flag name with "GLOG_", e.g.
   GLOG_logtostderr=1 ./your_application
The following flags are most commonly used:

logtostderr (bool, default=false)
Log messages to stderr instead of logfiles.
Note: you can set binary flags to true by specifying 1, true, or yes (case insensitive). Also, you can set binary flags to false by specifying 0, false, or no (again, case insensitive).
stderrthreshold (int, default=2, which is ERROR)
Copy log messages at or above this level to stderr in addition to logfiles. The numbers of severity levels INFO, WARNING, ERROR, and FATAL are 0, 1, 2, and 3, respectively.
minloglevel (int, default=0, which is INFO)
Log messages at or above this level. Again, the numbers of severity levels INFO, WARNING, ERROR, and FATAL are 0, 1, 2, and 3, respectively.
log_dir (string, default="")
If specified, logfiles are written into this directory instead of the default logging directory.
v (int, default=0)
Show all VLOG(m) messages for m less or equal the value of this flag. Overridable by --vmodule. See the section about verbose logging for more detail.
vmodule (string, default="")
Per-module verbose level. The argument has to contain a comma-separated list of <module name>=<log level>. <module name> is a glob pattern (e.g., gfs* for all modules whose name starts with "gfs"), matched against the filename base (that is, name ignoring .cc/.h./-inl.h). <log level> overrides any value given by --v. See also the section about verbose logging.
There are some other flags defined in logging.cc. Please grep the source code for "DEFINE_" to see a complete list of all flags.

Используется ctags (exuberant-ctags) для создания библиотеки перекрестных ссылок в исходных текстах
Файл tags создается командой:
ctags -R --c++-kinds=+p --fields=+iaS --extra=+q .

Используется cppcheck для статической проверки исходных текстов:
cppcheck . --force -Icmake -Imdp -I../libzmq/src -Imsg -Itools -Ixdb/impl -Ixdb/rtap -Ixdb/broker -I../eXtremeDB_5_fusion_eval/include -I../glog-0.3.3/src -I../gtest-1.7.0/include -Iclient -Iworker

Подробная трассировка тестов включается с помощью:
ctest -R НАЗВАНИЕ_ТЕСТА -VV

Хронология проблем:
--------------------------------------------------------------------------------
04.03.2013 = Решено
Worker не получает сообщения от Брокера. После нескольких безответных (с точки зрения worker-а) попыток передачи HEARTBEAT сервис перезапускается. Эта ситуация диагностируется Брокером успешно.

13.03.2013 
Проблема от 04.03.2013 решена. Исправлена ошибка в поле сообщения, используемая протоколом ZMQ в качестве адресата.

14.03.2013
Бинарная совместимость с протоколом Majordomo 0.2.0 

15.03.2013
Опробована работа под Solaris 9:
- всей связки целиком
- брокер на linux, служба в solaris
Обнаружено постепенно увеличивающееся с каждой итерацией количество сообщений HEARTBEAT, 
посылаемых службе единовременно. 

27.08.2013
У библиотеки ZMQ (как минимум в 3.2) есть потенциальная проблема с сокетами ROUTER:
если удаленная сторона не отвечает на запрос, происходит утечка памяти. 
An unavoidable memory leak in ROUTER sockets when there is pending data for clients who will never return.
Ссылка на статью: http://gonitro.io, https://github.com/bumptech/nitro

11.09.2013 = Решено
Чтение содержимого сериализованных полей Сообщения из базы данных завершается без ошибок, но данные не соответствуют исходным. Была проблема в некорректном указании длины строки, читаемой из БД, для последующей десериализации.

13.09.2013 = Решено
Нарушение уникальности ключа PK_expire_for_service у Letter приводило к невозможности иметь более одного экземпляра
сообщения в БД с одинаковыми секундными отметками времени. Однако у одной Службы может быть несколько одновременно
поступивших изменений, пришлось убрать тег unique с этого индекса.

05.02.2015
В некоторых случаях Клиент, начиная новый(ые) запрос(ы) после паузы, не получает ответа от Службы.
В этот период (2.5сек) Служба не может ответить, поскольку находится внутри вызова sleep(HeartbeatInterval)
после обнаружения необходимости переподключения к Брокеру.
Проблема в том, что после завершения обработки Службой последнего запроса Клиента прошло время,
превышающее таймаут, а Служба в этот период не посылала HEARTBEAT Брокеру. Нужно следить за периодичностью
запросов HEARTBEAT в адрес Брокера на стороне Службы.

TODO
--------------------------------------------------------------------------------
Требование:
Проверить возможность использования std::string в качестве полезной нагрузки.
Можно ли хранить protobuf в std::string? Стоит перейти на zframe вместо string?
Ответ:
Тип данных string пригоден для хранения UTF-8 и бинарных данных. Локализованные строки нормально хранятся и
читаются из Базы данных.

Требование:
Рассмотреть возможность внедрения поддержки UNICODE, используя библиотеку ICU.

Версия 3.5 eXtremeDB не поддерживает неуникальные таблицы хешей. Множество одинаковых 
значений могут содержать только деревья. Хеши версии 4.1 и выше могут содержать 
неуникальные ключи. Так как текущая версия БД равна 3.5, но впоследствии планируется 
переход на 4.1, можно использовать хеши. Это повлечет ограничение - у каждого Сервиса 
может быть только один Обработчик. После перехода на 4.1 это ограничение можно снять. 
Или в 3.5 использовать деревья, а после миграции на 4.1 перейти на хеши, меньше 
накладных расходов.

Требование:
PushWorker() для существующего Обработчика обновит его поле состояния, оставив все остальное 
без изменений. Возможно требуется очистка полей этого Экземпляра - удаление связанных 
Сообщений и т.п.

Требование:
Значения интервалов HEARTBEAT у Брокера и Обработчиков задаются в разных местах. Нужно объединить.
Решение:
Период HEARTBEAT задается в config.h.

Требование:
Проверить условия получения идентификатора отправителя "mmi.*", это приводит к удалению Обработчика.
Решение:
Это название Службы, к которой адресовано служебное сообщение.

Рассмотреть необходимость присутствия в заголовке строковых полей "Отправитель" и "Адресат". Эта информация
дублирует систему идентификаторов (IDENTITY), и увеличивает размер заголовка.

Выбирать из очереди сообщений для передачи их свободному Обработчику следует те экземпляры, 
которые ждут своей очереди более остальных.

Проверить, верно ли что: возврат из mdcli->recv() с нулевым сообщением означает получение ответа 
на сообщение, просроченного более чем на 2 секунды? К примеру, запрос был послан 2.5 секунды назад, 
и только что получен ответ, хотя сокет DEALER его уже не ждал?

Требование: Минимизировать количество ходящих сообщений HEARTBEAT. Если от процесса было сообщение не далее чем 
величина интервала HEARTBEAT, не посылать ему этот запрос. В файле mdp_broker.cpp, функция worker_waiting(), 
строка 685, не вызывается worker_send(HEARTBEAT...) согласно zguide/C/mdbroker.c
Решение:
Не посылать HEARTBEAT-сообщение для процессов, интенсивно обменивающихся с Брокером. Коммит b4b92b3.

Требование:
Ввести в Брокере фоновую нить, проверяющую наличие устаревших Обработчиков и Сообщений.
Если Обработчик устарел, и не имеет связанного сообщения, удалить его из БД.
Если Сообщение устарело, передать его на исполнение другому обработчику или ответить Клиенту отказом.

Требование:
Убрать общие детали реализации MCO внутрь класса-имплементации DatabaseImpl для DatabaseBrokerImpl.
Сейчас внутри DatabaseBrokerImpl часть функций дубируется в для DatabaseImpl, причем перевес в реализации
на стороне DatabaseBrokerImpl. Из возможностей DatabaseImpl используется только получение имени БД и функции
смены внутренних состояний.

Требование:
Обеспечить для Клиента хранение в постоянном хранилище запросов, поданных Брокеру с его стороны.
После аварийного перезапуска Клиента обеспечить повторную отправку этих запросов Брокеру. Клиенту 
при получении ответа на запрос нужно удалять его запись из постоянного хранилища.
Предложение - при аварийном перезапуске Клиент уведомляет об этом Брокера, и тот сам повторно
передает запросы Клиента Службам (что при этом произойдет с идентификатором Клиента?)

Удаленные сетевые и локальные репозитории
На gev-book добавлен сетевой репозиторий gev@gev-itg:/var/git/rtdbus.git
На gev-itg добавлен локальный промежуточный репозиторий integration
  gev@gev-itg:/var/git/rtdbus.git$ git remote -v
    origin  /home/gev/ITG/sandbox/rtdbus (fetch)
    origin  /home/gev/ITG/sandbox/rtdbus (push)
  gev@gev-book ~/ITG/rtdbus $ git remote -v
    origin  gev@gev-itg:/var/git/rtdbus.git (fetch)
    origin  gev@gev-itg:/var/git/rtdbus.git (push)
  gev@gev-itg:~/ITG/sandbox/rtdbus$ git remote -v
    integration   /var/git/rtdbus.git (fetch)
    integration   /var/git/rtdbus.git (push)
    origin    git@bitbucket.org:gev76/rtdbus.git (fetch)
    origin    git@bitbucket.org:gev76/rtdbus.git (push)

==========================================================
(gdb) print *((mco_db_connection_t*)(con0))
{
  conn_id = 0,
  tran_seq = 77,
  status = 0,
  curr_obj_class = 2,
  curr_obj = 0, 
  dm = 
  {
    hdr = 0x0,
    pages = 0x0,
    file = 0x0,
    log = 0x0, 
    logs = {0x0, 0x0},
    dirty_pages = 0x0,
    write_delayed_pages = 0x0,
    root_page = 0x0,
    btree_buf = 0x0,
    log_write_buf = 0x0,
    file_write_buf = 0x0,
    dbh = 0x0,
    con = 0x0,
    hash_table = 0x0, 
    page_data = 
    {
      0x0 <repeats 16 times>
    },
    updating = 0,
    mutex = 0x0,
    alloc_mutex = 0x0,
    policy = MCO_COMMIT_SYNC_FLUSH,
    n_committed_transactions = 0,
    truncate_log = 0,
    in_critical_section = 0,
    cache_enabled = 0,
    sems = 0x0,
    rw_locks = 0x0,
    alloc_callback = 
    {
      func = 0x0,
      threshold_kind = MCO_ALLOC_PERCENT_USED,
      threshold_value = 0,
      prev_value = 0
    },
    n_modified_pages = 0,
    n_precommitted_pages = 0,
    rc4_state = 0x0,
    page_cache = 
    {
      {timestamp = 0, access_count = 0, index = 0},
      {timestamp = 0, access_count = 0, index = 0},
      {timestamp = 0, access_count = 0, index = 0},
      {timestamp = 0, access_count = 0, index = 0}
    },
    curr_timestamp = 0
  }, 
  trans = 
  {
    active_trans_list = { next = 0, prev = 0}, 
    error_code = MCO_S_OK, 
    trans_no = 54, 
    snapshot_no = 53, 
    n_performed_transactions = 76, 
    latest_trans_no = 0, 
    n_level = 0, 
    flags = 0, 
    prio = 0, 
    isolation_level = MCO_REPEATABLE_READ, 
    type = MCO_READ_WRITE, 
    tm = 0xb5d257ec, 
    next = 0, 
    wait = 
    {
      flags = 0 '\000', 
      db_index = 0 '\000', 
      sync_index = 0
    },
    cleanup_period = 1, 
    private_vlist = 
    {
      head = 0,
      tail = 0,
      free = 0,
      first_pos = 0,
      curr_pos = 0,
      max_elems = 0,
      max_index = 0,
      size = 0
    },
    curr_vlist = 0xb5d2922c, 
    param = 0x0, 
    ha_iterator = 0x0, 
    commit_iterator = 0x0, 
    last_inspected_trans_no = 0
  }, 
  db = 0xb5d22144, 
  sync_data = 0xb5d257ac, 
  pmh = 0xb5d39780, 
  free_pages = 0xb5daef80, 
  n_free_pages = 220, 
  default_isolation_level = MCO_DEFAULT_ISOLATION_LEVEL, 
  index_table = 0xb5d2960c, 
  pm_inmem = 0xb7f70fa0 <inmemory_pm>,
  pset = 0xb5d2963c, 
  udfs = 0x0, 
  colls = 0x0, 
  iter_index = 0x0, 
  hnd_cache = 
  {
    {obj = 0, hnd = 0x0},
    {obj = 0, hnd = 0x0},
    {obj = 0, hnd = 0x0},
    {obj = 524364, hnd = 0xbfffeda8},
    {obj = 0, hnd = 0x0},
    {obj = 0, hnd = 0x0},
    {obj = 0, hnd = 0x0},
    {obj = 0, hnd = 0x0}
  },
  hnd_cache_index = 796,
  process_id = 1,
  wc = 
  {
    root = 0x0,
    head = 0x0,
    tail = 0x0,
    height = 0,
    size = 0,
    threshold = 0,
    n_entries = 63,
    n_children = 255,
    curr = 0
  },
  ctx = 0x0,
  leaf_page = 0x0,
  leaf_page_access_count = 0 '\000',
  leaf_page_access_kind = 1 '\001',
  btree_access_kind = 2 '\002',
  inside_delete_all = 0 '\000',
  voluntary_index = 0,
  check_constraints = 1,
  alloc_callback = 
  {
    func = 0x0,
    threshold_kind = MCO_ALLOC_PERCENT_USED,
    threshold_value = 0,
    prev_value = 0
  }, 
  iter_pages = {0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0},
  current_rcursor = 0,
  last_autoid = 24,
  emark = 21140
}

0000000 0000 0000 004d 0000 0000 0002 0000 0000
0000010 0000 0000 0000 0000 0000 0000 0000 0000
*
0000110 0036 0000 0000 0000 0035 0000 0000 0000
0000120 004c 0000 0000 0000 0000 0000 0000 0000
0000130 0000 0000 0000 0000 0000 0000 0002 0000
0000140 0002 0000 57ec b5d2 0000 0000 0000 0000
0000150 0001 0000 0000 0000 0000 0000 0000 0000
0000160 0000 0000 0000 0000 0000 0000 0000 0000
0000170 0000 0000 922c b5d2 0000 0000 0000 0000
0000180 0000 0000 0000 0000 0000 0000 2144 b5d2
0000190 57ac b5d2 9780 b5d3 ef80 b5da 00dc 0000
00001a0 0000 0000 960c b5d2 0fa0 b7f7 963c b5d2
00001b0 0000 0000 0000 0000 0000 0000 0000 0000
*
00001d0 0000 0000 004c 0008 eda8 bfff 0000 0000
00001e0 0000 0000 0000 0000 0000 0000 0000 0000
00001f0 0000 0000 0000 0000 0000 0000 031c 0000
0000200 0001 0000 0000 0000 0000 0000 0000 0000
0000210 0000 0000 0000 0000 0000 0000 003f 0000
0000220 00ff 0000 0000 0000 0000 0000 0000 0000
0000230 0100 0002 0000 0000 0001 0000 0000 0000
0000240 0000 0000 0000 0000 0000 0000 0000 0000
*
0000270 0000 0000 0000 0000 0018 0000 0000 0000
0000280 5294 0000                              
0000284


